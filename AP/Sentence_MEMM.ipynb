{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d2ea07",
   "metadata": {},
   "source": [
    "Simple first-order maximum entropy markov model with greedy decoding for data with span annotations in BIO notation.  This model predicts a label for every *sentence* in the input (and represents that time step as the bag of words within that sentence, along with the previous sentence tag).  This assumes the input file is one long document, only represents time step t through the words observed in sentence t (and not, e.g., the words in sentence t-1 or t+1), and uses greedy decoding (not Viterbi decoding), so lots of directions to build on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0e07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "import operator\n",
    "import nltk\n",
    "from scipy import sparse\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161225c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            if len(cols) >= 3:\n",
    "                label=cols[1]\n",
    "                text=cols[2]\n",
    "                x.append(text)\n",
    "                y.append(label)\n",
    "\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6889b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_feats(text):\n",
    "    feats={}\n",
    "    tokens=nltk.word_tokenize(text.lower())\n",
    "    for tok in tokens:\n",
    "        feats[tok]=1\n",
    "    return feats\n",
    "\n",
    "def get_text_feats_in_vocab(text, vocab):\n",
    "    all_feats=get_text_feats(text)\n",
    "    feats={}\n",
    "    for feat in all_feats:\n",
    "        if feat in vocab:\n",
    "            feats[vocab[feat]]=1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "177bdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vocab(x, y, min_feat_count=2):\n",
    "\n",
    "    vocab=Counter()\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        lastLabel=\"START\"\n",
    "        if i > 0:\n",
    "            lastLabel=y[i-1]\n",
    "\n",
    "        vocab[\"_y_i_1:%s\" % lastLabel]+=1\n",
    "\n",
    "        feats=get_text_feats(x[i])\n",
    "        for feat in feats:\n",
    "            vocab[feat]+=1\n",
    "\n",
    "    feats={}\n",
    "    for feat in vocab:\n",
    "        if vocab[feat] >= min_feat_count or feat.startswith(\"_y_i_1\"):\n",
    "            feats[feat]=len(feats)\n",
    "\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "708652dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, x, vocab):\n",
    "    # with greedy decoding, we make decision sequentially and commit to each one in turn.\n",
    "    preds=[]\n",
    "    prev_lab=\"START\"\n",
    "    for i in range(len(x)):\n",
    "        feats=get_text_feats_in_vocab(x[i], vocab)\n",
    "        # prev_lab here is the *prediction* for the previous time step.  For dev and test, we assume we don't\n",
    "        # have access to the true labels at those positions, so much rely on the predictions our model makes.\n",
    "        feats[vocab[\"_y_i_1:%s\" % prev_lab]]=1\n",
    "        X = sparse.dok_matrix((1, len(vocab)))\n",
    "        for fid in feats:\n",
    "            X[0,fid]=1\n",
    "        y=model.predict(X)[0]\n",
    "        preds.append(y)\n",
    "        prev_lab=y\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0417ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(x, y, feats):\n",
    "    F = len(feats)\n",
    "    D = len(x)\n",
    "    X = sparse.dok_matrix((D, F))\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        lastLabel=\"START\"\n",
    "        if i > 0:\n",
    "            lastLabel=y[i-1]\n",
    "        feat=\"_y_i_1:%s\" % lastLabel\n",
    "        X[i,feats[feat]]=1\n",
    "\n",
    "        this_feats=get_text_feats_in_vocab(x[i], feats)\n",
    "        for feat in this_feats:\n",
    "            X[i,feat]=1\n",
    "\n",
    "        Y.append(y[i])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1620eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(labels):\n",
    "\n",
    "    spans=[]\n",
    "    start=None\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "\n",
    "        parts=label.split(\"-\")\n",
    "        bio=cat=\"O\"\n",
    "        if len(parts) == 2:\n",
    "            bio=parts[0]\n",
    "            cat=parts[1]\n",
    "        else:\n",
    "            bio=parts[0]\n",
    "\n",
    "        if (bio == \"B\" or bio == \"O\") and start is not None:\n",
    "            s, last_cat=start\n",
    "            spans.append((idx-1,last_cat))\n",
    "            start=None\n",
    "\n",
    "        if bio == \"B\":\n",
    "            start=idx, cat\n",
    "\n",
    "    if start is not None:\n",
    "        s, last_cat=start\n",
    "        spans.append((len(labels)-1,last_cat))\n",
    "\n",
    "    return set(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc7ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_f1(pred_labels, true_labels):\n",
    "\n",
    "    cor=0\n",
    "    precision_n=0\n",
    "    recall_n=0\n",
    "\n",
    "    pred_spans=get_spans(pred_labels)\n",
    "    true_spans=get_spans(true_labels)\n",
    "\n",
    "\n",
    "    cor=len(pred_spans.intersection(true_spans))\n",
    "    precision_n=len(pred_spans)\n",
    "    recall_n=len(true_spans)\n",
    "        \n",
    "    precision=0\n",
    "    if precision_n > 0:\n",
    "        precision=cor/precision_n\n",
    "\n",
    "    recall=0\n",
    "    if recall_n > 0:\n",
    "        recall=cor/recall_n\n",
    "    F1=0\n",
    "    if precision+recall > 0:\n",
    "        F1=2*precision*recall/(precision+recall)\n",
    "\n",
    "    return F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4c7c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printWeights(log_reg, feature_vocab, n=10):\n",
    "\n",
    "    reverse_vocab=[None]*len(log_reg.coef_[0])\n",
    "    for k in feature_vocab:\n",
    "        reverse_vocab[feature_vocab[k]]=k\n",
    "\n",
    "    # binary\n",
    "    if len(log_reg.classes_) == 2:\n",
    "        weights=log_reg.coef_[0]\n",
    "\n",
    "        cat=log_reg.classes_[1]\n",
    "        for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "            print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "        print()\n",
    "\n",
    "        cat=log_reg.classes_[0]\n",
    "        for feature, weight in list(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1)))[:n]:\n",
    "            print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "        print()\n",
    "\n",
    "    # multiclass\n",
    "    else:\n",
    "        for i, cat in enumerate(log_reg.classes_):\n",
    "\n",
    "            weights=log_reg.coef_[i]\n",
    "\n",
    "            for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "                print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14d2a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid=20\n",
    "folder=\"splits/%s\" % gid\n",
    "trainFile=\"%s/train.txt\" % folder\n",
    "devFile=\"%s/dev.txt\" % folder\n",
    "testFile=\"%s/test.txt\" % folder\n",
    "\n",
    "train_x, train_y=read_data(trainFile)\n",
    "dev_x, dev_y=read_data(devFile)\n",
    "test_x, test_y=read_data(testFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22620f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Span F1 for best dev model: 0.341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab=get_feature_vocab(train_x, train_y)\n",
    "train_X_ids, train_Y_ids=featurize(train_x, train_y, vocab)\n",
    "\n",
    "best_dev_F1=0\n",
    "best_model=None\n",
    "\n",
    "for C in [0.1, 1, 10, 100]:\n",
    "    log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
    "    log_reg.fit(train_X_ids, train_Y_ids)\n",
    "\n",
    "    preds=greedy_decode(log_reg, dev_x, vocab)\n",
    "    dev_F1=get_span_f1(preds, dev_y)\n",
    "    if dev_F1 > best_dev_F1:\n",
    "        best_dev_F1=dev_F1\n",
    "        best_model=log_reg\n",
    "\n",
    "log_reg=best_model\n",
    "\n",
    "preds=greedy_decode(log_reg, test_x, vocab)\n",
    "test_F1=get_span_f1(preds, test_y)\n",
    "print(\"Test Span F1 for best dev model: %.3f\\n\" % test_F1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "174dccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\t4.173\tmurdered\n",
      "B\t3.479\tdies\n",
      "B\t3.383\tkilled\n",
      "B\t3.366\tunfortunately\n",
      "B\t3.307\tactually\n",
      "B\t3.247\tmurders\n",
      "B\t3.166\tvader\n",
      "B\t3.129\tmountain\n",
      "B\t3.081\trevealed\n",
      "B\t3.058\tsuddenly\n",
      "\n",
      "I\t3.706\twounded\n",
      "I\t3.093\tawakens\n",
      "I\t2.895\t_y_i_1:B\n",
      "I\t2.834\tperson\n",
      "I\t2.815\tsex\n",
      "I\t2.499\troom\n",
      "I\t2.305\tmaureen\n",
      "I\t2.153\tfall\n",
      "I\t2.082\ttem√ºjin\n",
      "I\t2.073\tbefore\n",
      "\n",
      "O\t3.538\tgame\n",
      "O\t3.263\twhom\n",
      "O\t3.201\tgawda\n",
      "O\t2.909\tupon\n",
      "O\t2.889\tvarious\n",
      "O\t2.642\tdate\n",
      "O\t2.449\trothbaum\n",
      "O\t2.392\ttemple\n",
      "O\t2.346\t_y_i_1:O\n",
      "O\t2.330\tplans\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printWeights(log_reg, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63b509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
